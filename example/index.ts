import 'dotenv/config';
import { ormGPT } from "../src/ormgpt";
import { Pool } from 'pg';  // PostgreSQL pool
import { PostgresAdapter } from "../src/PostgresAdapter";  // Import PostgresAdapter
import path from 'path';

// Check if the app is running in Docker
const isDocker = process.env.DOCKER_ENV === 'true';  // Check if running inside Docker

// Use conditional path for schema.sql based on the environment
const schemaFilePath = isDocker
  ? '/usr/src/app/example/schema.sql'  // Path for Docker container
  : path.resolve('./example/schema.sql');  // Path for local machine

(async () => {
  // Create a PostgreSQL connection pool
  const pgPool = new Pool({
    host: process.env.POSTGRES_HOST || 'localhost',
    port: 5432,
    user: process.env.PG_USER || 'postgres',
    password: process.env.PG_PASSWORD || 'War@123PG',
    database: process.env.PG_DB || 'ormgpt',
  });

  const postgresAdapter = new PostgresAdapter({
    client: pgPool,  // Pass the PostgreSQL client to PostgresAdapter
  });

  const ormgpt = new ormGPT({
    apiKey: process.env.HUGGING_FACE_API_KEY || "",  // Use Hugging Face API key
    schemaFilePath: schemaFilePath,  // Use the dynamically set schema file path
    dialect: "postgres",  // SQL dialect
    dbEngineAdapter: postgresAdapter,  // Pass the PostgresAdapter
    apiUrl: "https://api-inference.huggingface.co/models/facebook/llama-2-7b",  // LLaMA model endpoint
    model: "facebook/llama-2-7b",  // Using LLaMA model by default
  });

  // Example usage
  const userQuery = "Give me all users who ordered a laptop.";  // Example user query
  try {
    const sqlQuery = await ormgpt.getQuery(userQuery); // Get SQL query generated by Hugging Face
    console.log("Generated SQL query:", sqlQuery); // Log the generated SQL query
  
    // Execute the query on the database
    const queryResult = await ormgpt.query(sqlQuery);
    console.log("Query result:", queryResult); // Log the query result from the database
  } catch (error) {
    console.error("Error:", error);
  }
})();
